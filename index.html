<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Joachim Bellet – Neuroscience, Memory & Consciousness</title>
  <!--
    Update the metadata to reflect the broader focus on sensory memory, internal models and conscious perception.
  -->
  <meta name="description" content="Homepage of Joachim Bellet, neuroscientist investigating sensory memory, internal models and conscious perception." />
  <meta property="og:title" content="Joachim Bellet – Neuroscience, Memory & Consciousness" />
  <meta property="og:description" content="Homepage of Joachim Bellet, neuroscientist investigating sensory memory, internal models and conscious perception." />
  <meta property="og:image" content="assets/og-card.jpg" />
  <meta property="og:type" content="website" />
  <link rel="icon" href="assets/favicon.ico" />
  <style>
    /* Base colour palette using CSS variables for light/dark theme */
    :root {
      --bg: #fdfdfd;
      --text: #111827;
      --accent: #2563eb;
      --link: #1d4ed8;
      --muted: #6b7280;
      --card: #ffffff;
      --border: #e5e7eb;
    }
    @media (prefers-color-scheme: dark) {
      :root {
        --bg: #0b1120;
        --text: #f1f5f9;
        --accent: #3b82f6;
        --link: #60a5fa;
        --muted: #94a3b8;
        --card: #1e293b;
        --border: #334155;
      }
    }
    * {
      box-sizing: border-box;
    }
    body {
      margin: 0;
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      background-color: var(--bg);
      color: var(--text);
      line-height: 1.6;
    }
    header {
      position: sticky;
      top: 0;
      backdrop-filter: blur(8px);
      background-color: rgba(253, 253, 253, 0.8);
      border-bottom: 1px solid var(--border);
      z-index: 10;
    }
    nav {
      display: flex;
      justify-content: space-between;
      align-items: center;
      max-width: 1100px;
      margin: 0 auto;
      padding: 1rem;
    }
    nav a {
      color: var(--link);
      margin-left: 1rem;
      text-decoration: none;
      font-weight: 500;
    }
    nav a:hover {
      text-decoration: underline;
    }
    .hero {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      text-align: center;
      padding: 6rem 1rem 4rem;
      background-image: linear-gradient(180deg, var(--bg), var(--card));
    }
    .hero h1 {
      font-size: 2.5rem;
      margin-bottom: 0.5rem;
    }
    .hero p.tagline {
      font-size: 1.25rem;
      color: var(--muted);
      max-width: 700px;
      margin-bottom: 1rem;
    }
    .hero .cta {
      display: inline-block;
      margin-top: 1rem;
      padding: 0.75rem 1.5rem;
      background-color: var(--accent);
      color: #fff;
      border-radius: 0.375rem;
      text-decoration: none;
      font-weight: 600;
      transition: background-color 0.2s;
    }
    .hero .cta:hover {
      background-color: var(--link);
    }
    section {
      max-width: 800px;
      margin: 0 auto;
      padding: 2rem 1rem;
    }
    h2 {
      font-size: 1.75rem;
      margin-top: 2rem;
      margin-bottom: 1rem;
      border-bottom: 2px solid var(--border);
      padding-bottom: 0.5rem;
    }
    .pub-list {
      list-style: none;
      padding: 0;
      margin: 0;
    }
    .pub-item {
      margin-bottom: 1.5rem;
      background-color: var(--card);
      border: 1px solid var(--border);
      border-radius: 0.5rem;
      padding: 1rem;
    }
    .pub-item h3 {
      margin-top: 0;
      font-size: 1.1rem;
    }
    .pub-item p {
      margin: 0.5rem 0 0;
    }
    footer {
      text-align: center;
      padding: 2rem 1rem;
      color: var(--muted);
      border-top: 1px solid var(--border);
    }
    .profile-img {
      width: 160px;
      height: 160px;
      border-radius: 50%;
      object-fit: cover;
      border: 4px solid var(--border);
      margin-bottom: 1.5rem;
    }
    @media (min-width: 768px) {
      .hero h1 { font-size: 3rem; }
      .hero p.tagline { font-size: 1.5rem; }
    }
  </style>
</head>
<body>
  <header>
    <nav>
      <div><strong>Joachim Bellet</strong></div>
      <div>
        <a href="#research">Research</a>
        <a href="#publications">Publications</a>
        <a href="#bio">Bio</a>
        <a href="#contact">Contact</a>
      </div>
    </nav>
  </header>
  <main>
    <section class="hero">
      <img src="assets/portrait.jpg" alt="Portrait of Joachim Bellet" class="profile-img" />
      <h1>Joachim Bellet</h1>
      <p class="tagline">Neuroscientist investigating sensory memory, internal models and conscious perception</p>
      <p>Post‑doctoral researcher in Markus Siegel’s laboratory at the
        Magnetoencephalography (MEG) Centre, University of Tübingen. Previously I worked with Timo van Kerkoerle, Bechir Jarraya, Theofanis Panagiotaropoulos and Stanislas Dehaene at NeuroSpin (CEA/Paris‑Saclay).</p>
      <a href="#contact" class="cta">Get in touch</a>
    </section>

    <section id="research">
      <h2>Research interests</h2>
      <p>
        My work investigates the neural mechanisms that allow fleeting sensory inputs to be
        transformed into stable conscious experience. I use large-scale multi‑electrode
        recordings in non‑human primates to decode how ensembles of neurons in the
        ventrolateral prefrontal cortex encode visual stimuli, maintain short‑term
        memory traces, and build predictive internal models of the world. I am broadly
        interested in how these processes support perception, memory and decision making.
      </p>
      <ul>
        <li>
          <strong>Decoding sensory representations.</strong>
          Population activity in prefrontal cortex can reliably encode visual stimuli on
          the order of tens of milliseconds. Even when perception is challenged by rapid
          serial presentation, stimulus identity can be decoded early and fades as new
          stimuli arrive【114942373471833†L306-L333】.
        </li>
        <li>
          <strong>Internal models and predictive coding.</strong>
          Prefrontal ensembles form overlapping representations that capture both the
          identity of visual events and abstract sequence structure. These neural codes
          reflect expectations, mismatches and updates—consistent with predictive coding
          theories【682652431670720†L29-L66】.
        </li>
        <li>
          <strong>Distortions in sensory memory.</strong>
          Short‑term memory does not simply preserve high‑fidelity sensory input.
          Studies of foveal vision reveal that remembered target locations are
          systematically mislocalized, with the largest distortions for the most
          central targets【728724067437846†L311-L324】. Such findings challenge the
          assumption that sensory memory is a veridical copy and inform models of
          perceptual stability.
        </li>
        <li>
          <strong>Microsaccades and neural oscillations.</strong>
          Tiny eye movements called microsaccades modulate neural activity and behavior.
          In my Ph.D. work, I designed deep‑learning algorithms to detect these rare events
          and showed that beta and alpha oscillations are locked to microsaccades generation,
          leading to long modulations in contrast sensitivity and reaction times【944961400717940†L93-L160】. This work underscores how even subtle motor events can shape sensory processing.
        </li>
      </ul>
    </section>

    <section id="publications">
      <h2>Selected publications</h2>
      <ul class="pub-list">
        <li class="pub-item">
          <h3>Spontaneously emerging internal models of visual sequences combine abstract and event‑specific information</h3>
          <p><em>Cell Reports</em>, 2024 (with M.E. Bellet, M. Gay, B. Jarraya, S. Dehaene, T. van Kerkoerle &amp; T.I. Panagiotaropoulos)</p>
          <p>
            We recorded neuronal populations in ventrolateral prefrontal cortex while macaques
            passively viewed visual sequences. The same neurons encoded both the specific
            images being shown and the abstract structure of the sequence; these representations
            updated rapidly when a mismatch occurred and generalized across different sequences【604572266711707†L87-L110】.
          </p>
        </li>
        <li class="pub-item">
          <h3>Decoding rapidly presented visual stimuli from prefrontal ensembles without report nor post‑perceptual processing</h3>
          <p><em>Neuroscience of Consciousness</em>, 2022 (with M. Gay, A. Dwarakanath, B. Jarraya, T. van Kerkoerle, S. Dehaene &amp; T.I. Panagiotaropoulos)</p>
          <p>
            We demonstrated that ventrolateral prefrontal cortex population activity
            reliably encodes the identity of visual stimuli within ~60 ms, even under
            conditions that reduce post‑perceptual processing. Decoding accuracy
            drops as new stimuli appear, raising questions about whether this activity
            reflects conscious access, phenomenal content or preconscious waves【114942373471833†L306-L333】.
          </p>
        </li>
        <li class="pub-item">
          <h3>Severe distortion in the representation of foveal visual image locations in short‑term memory</h3>
          <p><em>Proceedings of the National Academy of Sciences</em>, 2022 (with K.F. Willeke, A.R. Cardenas &amp; Z.M. Hafed)</p>
          <p>
            Contrary to the assumption that short‑term memory faithfully preserves
            high‑acuity foveal input, we discovered that remembered foveal targets
            are systematically mislocalized. The largest errors occurred for the
            most central targets, illustrating that the neural representation of
            sensory memory can be surprisingly distorted【728724067437846†L311-L324】.
          </p>
        </li>
      </ul>
    </section>

    <section id="bio">
      <h2>Biography</h2>
      <p>
        I am a neuroscientist fascinated by how the brain builds internal representations of the world. I received my Ph.D. in
        systems neuroscience at the Werner Reichardt Centre for Integrative Neuroscience, University of Tübingen, where I worked
        with Ziad M. Hafed on microsaccades, neural oscillations and machine‑learning methods for detecting rare events.
        Following my doctorate I joined the Cognitive Neuroimaging Unit at NeuroSpin (CEA/Paris‑Saclay) to collaborate with
        Theofanis Panagiotaropoulos, Timo van Kerkoerle, Bechir Jarraya and Stanislas Dehaene on prefrontal neural codes and internal models. Since November 2022
        I have been a post‑doctoral researcher in Markus Siegel’s laboratory at the Magnetoencephalography (MEG) Centre of the
        University of Tübingen. My long‑term research aims to understand how transient sensory inputs and memory traces interact
        to generate stable conscious experience and behavior.
      </p>
      <p>
        Outside of the lab, I enjoy exploring cultural life, engaging in science outreach and mentoring younger scientists.
      </p>
    </section>

    <section id="contact">
      <h2>Contact</h2>
      <p>
        I welcome collaboration and scientific discussions. Feel free to email me at
        <a href="mailto:joachim.bellet@cin.uni-tuebingen.de">joachim.bellet@cin.uni-tuebingen.de</a>. You can also follow my open-source work on
        <a href="https://github.com/jobellet" target="_blank" rel="noopener">GitHub</a>, or connect on
        <a href="https://www.linkedin.com/in/joachim-bellet-449a1483" target="_blank" rel="noopener">LinkedIn</a>.
        I am always interested in collaborations and discussions about neural coding,
        sensory memory and consciousness.
      </p>
    </section>
  </main>
  <footer>
    &copy; 2025 Joachim Bellet. All rights reserved.
  </footer>
  <script>
    // optional: smooth scrolling for navigation links
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          target.scrollIntoView({ behavior: 'smooth' });
        }
      });
    });
  </script>
</body>
</html>
